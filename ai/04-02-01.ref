==========
So the subject matter for today is kind of the leftovers of planning and acting. 
So we're just about to finish up thinking about planning and acting in deterministic domains, and then starting on Wednesday we're going to move into probabilistic sort of representations of uncertainty in the world. 
==========
So, in all the planning stuff we've looked at so far, we've assumed a couple things. 
We've assumed that we know a complete and correct model of the world dynamics .... 
Right, that's what the operator descriptions are. 
And we've assumed that we know the initial state. 
And we've sort of implicitly assumed that the world is deterministic. 
That is to say, whenever it's in some state and we take an action, then it does whatever the operator description tells us it's going to do. 
So this is related to knowing a complete and correct model. 
But not only is it a complete and correct model, it's a deterministic model. 
Now, there are some kinds of sort of formal domains maybe for which these kinds of settings are true. 
So, for instance, you know, planning methods just like the ones we've been looking at have been applied in real application domains for things like scheduling, where the assumption is you're already working in an abstraction of a domain that everybody kind of believes is right, and the abstraction -- you know the initial state; you know how long it's going to take this machine to process that job, or at least the approximation is good enough. 
But for all kinds of other domains, these things aren't necessarily satisfiable. 
OK. 
So, today what we're going to do is talk about ways of addressing some of these problems without moving directly yet to probabilistic representations, but it will be a motivation for going to probability pretty soon, because this is kind of meant to be a segue. 
This we'll address later on really by learning. 
So we're not going to get to this problem today. 
But these things can be addressed -- I mean, at least to deal with not knowing your initial state or not knowing it exactly, and to deal with nondeterminism in the world, we can look at conditional planning and various kinds of re-planning. 
So, that's what we're going to do today. 
We're going to look at some conditional planning methods that are appropriate when you don't know everything about the state of the world. 
And we're going to look at re-planning, which is appropriate when the world is nondeterministic, when there can be in some sense errors in the execution of the actions, but that you maybe are not prepared or interested in modeling those errors in advance. 
==========
All right, let's talk about conditional planning. 
So, let's imagine that we want to make a plan to go to the airport and get on our airplane, but in order to do that pretty much everybody -- there's no way to know in advance what gate to go to, right? 
You can't make a plan that says I'm going to go to the airport and then I'm going to Gate 57 and I'm going to get on an airplane, because you don't know what gate your flight is going to be at, at the beginning of the time that you need to make the plan. 
And in fact in this case there's really no way to know; it's usually not determined until later. 
But in other cases it might be that there's some piece of information that's known to someone, it's just not known to you. 
But at the planning time if you don't know some piece of information then you're going to need to make a plan that says something like I'm going to go to the airport, I'm going to look at the screen that says what gate my flight goes from, and then I'm going to go to whatever gate the screen tells me I need to go to. 
So that kind of thing is not handle-able in our current scenario, but we can modify something like the partial order planner pretty easily to deal with this. 
So let's look at how to do that. 
Rather than writing the algorithm out in complete detail, I think we'll just go through an example, and you can read -- the book has a nice description of the details of the algorithm. 
So, let's imagine that we have a partial order planning problem. 
We have the following operators -- let's see. 
"read gate" will be an operator. 
And it's going to have a precondition, that we're at the airport, and we're going to have to abbreviate here -- "at airport lobby" -- well, I'll write it out and show you how to abbreviate later. 
So we're at the airport lobby, and it's going to have the effect -- the effect is interesting. 
What's the effect of reading the gate number on the monitor at the airport? 
Well, it doesn't change where you are, it changes your brain, right? 
So you can say, well, the effect is that you know, in this case let's consider an airport that has two gates, so either you're at Gate 1 or you're at Gate 2. I've been to some airports that have two gates. 
So, we're going to know whether Gate 1 ... 
we're going to know whether the airplane is at Gate 1. 
All right, so this is a case where we have something that has, as an effect, knowledge. 
And so what we're going to be able to do now is make a plan that goes along and at some point it executes this operator of reading the gate, and then depending on the answer it gets it's going to be able to do different things. 
It's going to be a plan with a branch in it. 
I'll write the rest of the operators up here, and we'll go ahead and make the plan. 
So, let's see. 
We can have an operator "boards the plane." 
We'll have two versions of this operator. 
We'll have "board Plane 1" and "board Plane 2." So the preconditions for "board Plane 1" are going to be that our plane is at Gate 1 and we are at Gate 1 and the effect is going to be that we're on the plane. 
And we can have another operator "board Plane 2" -- you could do this with parameters; I'm just trying to make it as simple as we can -- the preconditions of which would be that our flight is not at Gate 1 and that we are at Gate 2, and the effect will be that we are on our plane. 
To read the gate we have to be at the lobby, so now we just need some go-to's and we'll be done. 
So we'll need a "go to lobby" -- that's an operator -- and "go to G1" and then "go to G2." 
It does have the preconditions and effects that you would guess, right? 
In fact, let's just make these completely straightforward so that we don't have any -- and if the preconditions of going to the airport lobby be that we're at home, the effects are that we're at the lobby. 
We can only go to the gate from the lobby, so we'll say that the preconditions are "at lobby" and the effects are "at G1"; preconditions "at lobby" and we've got "at G2". 
There's our problem. 
==========
So, we're going to start "at home" and we'd like to finish "on the plane." 
That's what we'd like to do. 
So what are you trying to do in the partial order planner the way you know it? 
What would be the -- you know, when we start to run the partial order planning algorithm, what do you do? 
__: (inaudible) Try to satisfy an unfulfilled precondition. 
So "on plane" looks like an unfulfilled precondition. 
What operator should we use? 
__: (inaudible) "board Plane 1" or "board Plane 2." Let's pick "board Plane 1." 
That seems to produce "on plane." 
I guess we also have to have some more effects here. 
I'm sorry. 
So we're going to have to have "!Athome" 
... 
"!Atlobby" 
... 
"!Atlobby" 
... 
"!AtG1" 
... 
"!AtG2." 
OK, so "board 1" produces "on plane" and it also produces "!Atlobby." 
Its preconditions are that Gate 1 is true ... 
and we're at the lobby. 
So far, so good? 
Now what can we do? 
We have to satisfy one of these unsatisfied preconditions. 
OK, what preconditions should we work on? 
Let's work on "AtGate1" because that seems like we know how to do it. 
So "AtGate1" -- how do we get to be at Gate 1? 
Well, we "Go to Gate 1", right? 
That's not too hard. 
OK, so, we can do "go to Gate 1." 
So that would produce "at Gate 1"; it will also produce "not at lobby." 
It requires "at lobby." 
OK, and let's try to do that "at lobby." 
We can do that by going to the lobby. 
That produces "at lobby." 
It starts at "at home." 
It produces "not at home." 
OK, so, so far this looks like a really good plan, right? 
The only issue is we seem -- we have this Gate 1 hanging out here. 
So this is all predicated on Gate 1 being the place that our flight's taking off from. 
So there's another way to satisfy a precondition, and that is to try to figure out whether it's true, to put an explicit step in your plan that tests the world to see if that precondition is true. 
So we can put a step in our plan that tests whether Gate 1 is true or not. 
So let's have a plan step; it's called "ReadGate." 
It has a precondition that we're at the lobby, and it has as an effect knowing whether or not Gate1 is true. 
So we're going to put a special kind of link here, called a conditional link; and we're going to say... 
true. 
If Gate 1 is true, then that satisfies this precondition. 
Now, as soon as you do that -- when you add one of these conditions in -- in substance the idea is that you've decided that your plan is going to bifurcate. 
After you do this action, there's going to be a set of things that you do if it came out true, and a different set of things that you do if it comes out false. 
And you don't have to worry about conflicts between the things that you're going to do in the true case and the things you're going to do in the false case because you know that only one of these things is going to happen. 
So now we're going to introduce the notion of a context. 
A context is essentially the set of tests that I've done before now in the plan. 
And when we look for conflicts we're going to say that -- for threats, for instance -- that a threat can only happen within a single context. 
So an action that we intend to do if our plane leaves from Gate1 can't possibly threaten something that we're thinking about doing if the plane leaves from Gate2. 
So those are really just separable. 
Sso now we have these actions that have to depend on the answer of reading the gate, and we're going to add a context condition to that. 
So we're going to say that this action is only going to be useful, when Gate 1 is true. 
So we're going to put a condition on here of Gate 1 (writes). 
And, furthermore, this finish condition is going to be a special finish condition for Gate 1 because we're decided that -- right? 
The plan is going to finish one way if Gate 1 is true. 
The plan is going to finish potentially a completely different way if Gate 1 is false. 
So we put a condition on here also of "Gate 1." 
And when you put a condition on the finish, we actually have to add a new finish ... 
and the condition on this finish is "not Gate 1." 
For a minute there we felt like we were close to having a correct plan. 
All we have is this one precondition that we had to satisfy, but now we've kind of opened up some cans of worms, right? 
We satisfied this precondition all right by putting in this testing action. 
Now we have to worry about its preconditions plus we have to do this whole other plan. 
We can satisfy "at lobby" pretty easily presumably; we can do that. 
Do we have any threats to any constraints here? 
Let's not -- don't worry about that other Gate 1 yet, but look at the plan as it stands now and let me know if there's anything we need to do. 
__: "Read gate" has to happen before you go to Gate 1. 
Good. 
"Read gate" has to happen before "go to Gate 1." 
Notice it's not -- I mean, intuitively you want to say, well, of course, "read gate" has to happen before "go to Gate 1" because it would be stupid to go to Gate 1 if you didn't know it was one you needed to go to. 
But the way this algorithm works, just kind of turning the crank, you just do it because it's a threat. 
We'll use the blue for temporal links. 
So, the deal is that "go to Gate 1" threatens this link here, right? 
So this is an "at lobby" link, and this makes "at lobby" false. 
So this action threatens that link, but we can fix it by being sure that this comes afterwards. 
So we're going to say this comes after that. 
OK, so I'm using white for causal, blue for temporal, orange for conditional. 
Three kinds of links. 
So there's a good enough plan for that part of the plan. 
Go to lobby, read the gate, go to Gate 1, get on airplane, we're done. 
Now I have to deal with this other goal over here. 
We have an unsatisfied precondition, "on plane." 
All right, we can satisfy "on plane" a couple different ways. 
We could try "board Plane 1" and probably your computer would, but let's not. 
Right? 
Because it will get into trouble if we do. 
So let's instead just -- right now I'm not invoking miraculous insight - - what'll happen if you try to do this and "board Plane 1" is that you'll get a conflict. 
But we'll just try it with "board Plane 2." That's going to satisfy "on plane"; it's going to generate "not at Gate 2"; it's going to have as preconditions "not Gate 1" and "at Gate 2." Now, what we can do is notice -- well, we can do this in whatever order we want to, but the most interesting thing is this "not Gate 1." 
We have a way to satisfy "not Gate 1," which is to make this a condition of "read gate." 
The false link here ... 
can go there; we need the "not Gate 1" here. 
OK. 
So now what we need to do is to add an "at Gate 2." So we can do that ... 
(writes) ... 
and we can do that. 
"Go to Gate 2" produces "at G2", "not at lobby" Now, this presents a problem. 
What kind of problem does this present, the current situation? 
Is there a threat? 
__: The plane (inaudible). 
Right. 
This threat evolves out of that lobby thing that's over there. 
So it turns out that there's -- we added two new steps -- we added a new way to satisfy our precondition, which is to make it the effect of a sensing action, of a knowledge gaining action; and we are also adding now a new way of getting rid of a threat, and the new way of getting rid of a threat is to say I'm only going to do this action in some circumstance -- if you can add context to it. 
You can put this action in one half of the plan. 
So we can put this action in the half of the plan where we're not going to Gate 1, and everything will be OK. 
So we could just say, well, only do this if "not Gate 1." 
But in order to make that in that context it has to go after the thing that figures out that context condition. 
So it's going to have to go temporally after the "read gate." 
And now we can satisfy "at lobby" with "go to lobby" -- and I think we have a plan. 
__: (inaudible) Do we need to have the condition "Gate 1"? 
Ah, good. 
So, yes, we probably do have a conflict there now. 
And so now we have basically a plan that branches. 
It says go to the lobby, read the gate; if Gate 1 is true, then go to Gate 1 and board; otherwise, if Gate 1 is false, then go to Gate 2 and board. 
==========
So, this is a way to do conditional planning. 
At some level it's not too hard to talk about, but at another level it makes POP which is already not maybe the most efficient planning method pretty much go out of control. 
So this is a case of something that you can write down, and you can kind of make it work, but adding these new ways of fixing threats and satisfying preconditions means that the branching factor gets really big. 
So you could try to do things this way, but it's sort of hard. 
We might talk about ways to add conditions into GraphPlans, but that's pretty tricky, too. 
So this is pretty much now we're at the sort of frontier of classical planning research. 
When people work on planning methods, one of the things they do is try to understand how to extend them to the case of conditional planning -- if people are working on GraphPlan, SatPlan and those kinds of planning methods and thinking about how to do conditional versions of them. 
So we've kind of hit the frontier. 
An alternative to conditional planning of this sort -- well, you're going to do something like conditional planning if you really just don't know what the gate's going to be. 
An alternative is to have parameters and let the parameters propagate through, and it might be that you could formulate the plan and go in that way. 
Right? 
So you could say, well, there's some parameter which is the gate that I'm going to be at, and I'm going to have an operator which is "go to" the gate I'm going to be at, and you just let that variable get instantiated when you're going along. 
And that can actually make the -- and sometimes you need a little bit more complicated planning mechanism because you have to worry about variables and how they get bound and so on, but we've talked about this. 
But you can get a much more efficient planning algorithm if you just let that variable stay unbound through your whole plan. 
So you don't have to say, well, gosh, if it says I need to go to Gate 57, then I'll go to Gate 57, and if it says go to Gate 59, I'll go to Gate 59. 
Instead, you just say, I'll go there, I'll find out a binding for this variable, and I'll let that binding be a parameter for where I go after that. 
That's OK if you don't have to plan -- if you don't have to do different things depending on which different gate it's going to be. 
Right? 
So what if for some gates you have to just walk there and other gates you have to take the train? 
I think that's true at some airports. 
How do you deal with that? 
Do you make the conditional plan? 
What do you do? 
You go to the airport. 
This isn't an AI question. 
This is a how-do-you-think-about-airplanes question. 
What do you do in an airport? 
__: (inaudible) If you need to, then you go; but otherwise you don't. 
So, probably, -- so there's sort of two alternative stories that you could tell about what you do when you go to one of these airports. 
One is that, sitting at home or in the car or in the taxi or whatever, you make a conditional plan that says I'm going to go, I'm going to look at the thing, if it tells me I have to go somewhere that I go to by train then I'll go there by train and otherwise if it tells me to somewhere that I need to go by foot I'll go by foot. 
But that seems like kind of a pretty unlikely story, right? 
I mean all the time I go to airports that I have no idea whether they're going to involve taking trains to gates or not. 
Sometimes they do, sometimes they don't. 
So another story is forget that. 
I'm just going to plan again, later on, when I have the information. 
So another whole story is to not be so worried in advance about how it's all going to work out. 
Be a little more relaxed and plan on-line as the information becomes apparent to you. 
Now, that sort of approach doesn't suit NASA, right? 
Often. 
It doesn't suit people who want to have a theorem at the very beginning that they're going to for sure know exactly how to do what they're going to do. 
But for most of what we need to do in life there are too many conditions to do conditional planning, and so a more relaxed approach often works better. 
So let's talk a little bit about that. 
So re-planning. 
There's two things that re-planning is good for ... 
well, maybe a whole bunch, but one is this case that we just talked about where we don't really know yet how to do the thing that we're going to need to do. 
In that case, it's almost as if you can make a plan at a very high level of abstraction. 
So it's like you're going to say, well, I'm going to go to the airport, and then I'm going to go to the gate, and then I'm going to do some other stuff. 
And you can say, well, I go to the airport with a plan at this level of abstraction. 
So there's an idea that you might have a plan at a very high level of abstraction, but the details of how to go to the gate you don't know. 
And so what you're going to do is you're going to execute this plan until you get here, and then you're going to get information, and then you're going to call your planner -- you're going to figure out what to do based on the information you got, and that's going to enable you to figure out a plan for that and then do it -- so that when you get more information you can stop and re-plan. 
You would have to have some idea of the thing -- you were going to be able to do this, right? 
Just a sort of -- you know, making this high level plan is equivalent to having the self-confidence that you'll be able to find your way to the gate at the airport. 
Most of us believe we can do that. 
So you don't worry about the details; you figure I'll sort that out when I get there. 
So that's one time when you need to do re-planning. 
Another useful thing that we use re- planning there is not a case of not having information in advance but a case of having our model be not quite right, having execution errors happen. 
Right? 
So here's something that you could imagine doing, that you would make a plan, you call your planner, it takes as input an initial state, and what comes out is a plan. 
Now, you could execute that plan and executing a plan you can think of it as, well, you don't necessarily have this arrow, but so one version of executing a plan is just emitting the actions ... 
one by one. 
Right? 
So if you make a plan that says I'm going to do these four things, then you could execute that plan so-called "open-loop" -- you could just close your eyes and say, all right, Thing 1, Thing 2, Thing 3; and then maybe it works, maybe it doesn't. 
If you're in a world that has any kind of uncertainty or any kind of chance for error though, you probably don't want to close your eyes and just emit those actions. 
So the next level of thing that you could do presumably is generate an action, presumably it's going to go out and affect the world somehow, and then with any luck you'll be able to look and see what happened. 
Now, when you made the plan, the plan had some effect -- the particular action that you emitted was expected to have some effect in the world. 
So one thing that you can do, at least, is to check to see if the thing that you just did had the effect that you hoped that it would. 
So you can go along in a loop, doing actions and checking to see that they have the desired effect. 
If the effects are false -- if it's ever the case that the effects are false, that means I did a step, I thought it was going to ..., 
I tried to go out the door but, hmm, I'm not in the hallway. 
Well, you don't want to just do the next action. 
That would be dumb. 
So what you could do then is to just go back up here and say, well, that didn't work; let me re-plan. 
Right? 
I did some parts of my plan -- I did half of it, an action in the middle of it went wrong; but as long as I can see what the state of the world is, I can go back up here, I could take the current state of the world as the initial state, and I could plan what to do from here. 
So that's kind of a moderately flexible way of dealing with the world messing up our plan. 
Now, it doesn't try to anticipate anything. 
It doesn't try to think about what could go wrong and what to do if it did. 
It doesn't have a proof in its head that it can't deal with all the things that might go wrong. 
It just says I'm going to pretend that the world is deterministic; I'm going to make a plan that's good. 
If it is, I'm going to execute it; but I'm actually going to keep my eye out. 
I'm actually going to pay attention to see if things start to go wrong; and if they do, I'll plan again. 
So that was a pretty typical cycle for building plans, for building plans and kind of watching and executing. 
I'm going to talk about two other alternatives to this. 
So this is the kind of re- planning cycle.  
==========
OK, so, in re-planning, the idea is -- there is a couple things to think about, right? 
- - the idea is that planning and executing now are kind of intermingled, that I'm walking around in the world and I take some steps and then I notice something and I stop and think for a while and then I take some new steps and then I notice something and regroup. 
It might be that you're worried about computation time, that you're in a domain that has so much time pressure that you're worried that if you stop and re-plan, you know, the bad guys will get you while you're thinking. 
Or something -- you know, your race car will run into the wall, or some kind of bad time-critical thing will happen. 
In that case you might be worried about ever calling the planner because as you know or as you'll certainly find out these algorithms aren't always quick. 
And so there's a danger that you call this planner and it takes forever and there you are hung out and not knowing what to do. 
==========
There's a couple ways to get at that, but one idea which will come back again when we see uncertainty -- one idea is to make a universal plan ... 
You've heard in other contexts about the idea of a time-space tradeoff. 
The idea of universal planning is at the opposite extreme from this re-planning notion in the time-space tradeoff spectrum. 
So in universal planning the idea is that off-line computation is cheap, that space is cheap or plentiful or whatever, and that on-line computation is expensive. 
Now, so, if those three conditions hold for your domain, then it might be worth thinking really hard in advance, really kind of preparing yourself for everything that could happen, so that when you go out there into the world you can just do it. 
You just kind of don't have to stop and think. 
So the universal planning idea -- now -- I mean, at some level it's nuts, but it's worth talking about because it's the extreme end of the spectrum, of which the intermediate points are interesting. 
So what do you do? 
You plan for every possible initial state, and you store a mapping from the initial state into the first action of the plan. 
So you figure out a map, if the world is like this -- you think really hard and you say, if the world is like this, then I would have to do these ten actions in order to get to the goal. 
Now, you might think you had to store all ten of those actions, but you don't. 
You just have to store the first one, because as long as you execute the first one and assuming that you can see what the world is like after that, then you just go look that one up in the table somewhere. 
Now, you could compute this table by dynamic programming. 
It's not as horrible as it seems, and we'll actually talk about doing something like this in the probabilistic case. 
I'm not going to go through it in the deterministic case. 
But I guess there's one more assumption here, which is that the world is completely observable, meaning that we can really see what state the world is in. 
So, in every time step we would take an action, look to see what state the world is in, look it up in our table, do what action our table told us to do, see what state the world is in, and so on. 
OK, so that's one extreme. 
The other extreme in some sense is this one, replanning right? 
Here we don't store very much at all. 
All we store is this one little plan, but we might find ourselves having to think pretty hard on-line. 
I'm going to talk about one point that's in between these two things, mostly because I think it's neat and because it gives us some ideas about how to interpolate between these two because in a big domain this is way too expensive. 
It's way too expensive. 
Off-line computation can never be cheap enough, and space can never be plentiful enough, in a big domain - in the domain of your life. 
Why is your brain not simply a stored table of situations to actions? 
Well, the answer is that the table would just be way, way, way, way too big. 
So sometimes you have to stop and recompute. 
So this isn't a very efficient way to store a big policy, but it runs fast. 
Here we have the opposite problem. 
==========
So let's talk about an intermediate version, and the intermediate thing I'm going to talk about is something called a triangle table. 
These things were actually invented by Fikes and Nilsson as part of the original Strips planner. 
There was this project, it happened, was Shakey the Robot. 
Maybe someday I'll bring my Shaky the Robot with me because it's fun to watch. 
And Shakey really used Strips to figure out how to go, and Shakey was an actual robot. 
And they invented all kinds of things that were really important and in many ways haven't been so superseded. 
Let's consider -- we'll do the hardware store, drill, bananas, milk, supermarket example. 
So I'm just going to show you the triangle table. 
So here's the rough idea. 
A triangle table is a data structure that remembers the particular plan you made but some more information about why those steps are in the plan. 
In some sense the plan graph from GraphPlan kind of a code was information, as does the graph that you get from using POP. 
But in the triangle table it makes it very vividly clear an execution strategy for the plan. 
So it kind of -- we're going to make a plan in the ordinary way, but then we're going to develop an execution strategy that is a little bit more flexible and robust than simply emitting the actions in order. 
So I'm going to make a big table. 
So what's going to go in these places are the actions. 
So if you remember that problem, what we were going to do is go to the hardware store, buy a drill, go to the supermarket, buy bananas, buy milk. 
We'll leave buy milk off. 
Let's say that all we needed was bananas and a drill. 
OK, now what we do is -- the idea is that everything that's in one of these rows are preconditions for that action. 
So this is the preconditions for Action 0 in this row, ... 
and this is preconditions for Action 1, and this is preconditions for Action 2, and so on. 
And this last row is Goal conditions. 
And what goes in each column are -- let's see, things that are true in the initial state, things that are effects of Action 1, things that are effects of Action 2, things that are effects of Action 3, and things that are effects of Action 4. So what would go in this cell would be effects of Action 1 -- oh, I'm sorry. 
I did my numbering starting at 0 in one place and starting at 1 in the other place. 
Let me make this Action 1, Action 2, Action 3. 
So what would go in this cell is effects of Action 1 that are preconditions for Action 3 -- if there are any. 
It may be that we did Action 1 to set something up to enable us to do Action 3. 
If so, we put in this cell the things that this guy produces for that guy to consume. 
So we can put the preconditions in here and see how it goes. 
The preconditions for going to the hardware store -- if that's our first action, the preconditions for going to the hardware must be true in the initial state because there's nobody else who can produce them for us. 
And so the precondition for there was "at home." 
All right. 
Going to the hardware store produces "at hardware store." 
So we know "at hardware store" is going to be somewhere in this column. 
What row does "at hardware store" need to be in? 
This one here because "buy drill" needs it. 
So you do "at hardware store" here. 
OK. 
"Buy drill" also needs "sell hardware store drills." 
So that was true in the initial condition. 
OK. 
What does "buy drill" produce? 
"Have drill." 
So that needs to go somewhere in this column. 
Who needs "have drill"? 
The goal. 
So we'll put "have drill" down here. 
OK. 
"Go to supermarket" also requires "at hardware store." 
So we can copy that down here. 
That's OK. 
And it has as its effect that we're at the supermarket, and we're going to need that here. 
And to buy bananas we also need to know that the supermarket sells bananas. 
And there is also "have bananas" . 
Well, so that's just another way of writing down our plan, so what good is that? 
The answer is that it gives us a way to execute more flexibly, and the rule is to execute the highest true kernel. 
A kernel is a rectangle that includes the lower left corner ... 
Well, I think I just have to show you by example. 
Here's -- this is one kernel. 
That's a kernel, and this is a kernel. 
It includes the lower left corner and some upper right corner. 
That's it, right? 
So now the next upper right corner is this one, so this is a kernel, and this is an upper right corner so this is a kernel, and the bottom row is (inaudible). 
OK. 
Each of these kernels has an action associated with it, right? 
It's the action that's next to that upper right corner that we included. 
OK. 
The highest true kernel -- the highest kernel is this one. 
It's the one associated with the last action. 
And what it means for a kernel to be true is for all the conditions in the kernel to be true. 
So how would we execute this plan? 
We would look and see -- we would evaluate all the kernels starting from this one and working our way up to see which one is true. 
So first we would look at this, and we would say, well, if we have a drill and the supermarket sells bananas and we're at the supermarket, then independent of what we've done before or how we got here we should buy bananas. 
Now, there's just one more step to go, and if we do that everything is ready to go. 
So maybe, you know, serendipitously somebody gave us a drill. 
That's cool, and if we find ourselves in the supermarket with a drill, however we got here, we should just buy bananas. 
But, if not, then let's consider this other kernel. 
This other kernel is this one. 
It says if we're at the hardware store and we have a drill, what we should do is go to the supermarket -- again independent of how we got there. 
And then we have another kernel that says, well, if that's not true and we're at the hardware store but we don't have a drill, then we should buy a drill. 
So, what good is this? 
Well, one thing is that if, once these things happen to you, that if it just happens that you get advanced forward in your plan, then you wouldn't stupidly buy the drill again -- if somebody gave you a drill you wouldn't just buy it. 
The other thing that happens, which is more typical, is if something doesn't work out right -- like you find yourself at the hardware store and you decide to go to the supermarket but for some reason it doesn't work out, then you can at least look around and say, oh, gosh, here I am at the hardware store with a drill; I should go to the supermarket. 
And you would just keep trying to go to the supermarket until either you got there or some higher level thing says, mmm, that going to the supermarket thing really just seems to be broken. 
That's a case of your model not being right, and we'll address that later when we talk about learning. 
So, I just think that the triangle table idea is an interesting thing because it does more than just blindly execute the plan. 
It builds a little piece, just a little piece, of this universal plan table. 
It tells you for some particular circumstances what action you ought to take. 
And so what you would do if you made a triangle table is that you would make a picture sort of like this except rather than just executing the plan blindly, you would execute triangle table steps until either you reach the goal or none of the kernels is true. 
If none of the kernels in the triangle table is true, then there's nothing you can do in this planning table. 
It means the initial conditions are gone, and you're not in any sensible intermediate place, and so then you really are going to have to go back and re-plan. 
Now the added element, which is kind of interesting that Fikes and Nilsson did, was that after they made the triangle table and used it, they tried to learn some general new operations from it. 
And I'm not going to go into that stuff in detail, but you can read about it if you want. 
It's kind of neat. 
So they tried to put in some cache the results of doing this planning, but cache them in a sort of a general way, so that later one they could do some more problems after. 
They ran into some issues with doing that, but it's an interesting idea. 
So let me now back way up in preparation for undoing a whole bunch of stuff and going forward again next time. 
So, just in terms of AI history and stuff, all this -- so Strips happened in the mid-seventies I think; and after that people kind of worked on a variety of different planning algorithms and the sense was that the way to get a system to do something is to have it, you know, think about it, to meditate on the effects of its actions in different circumstances. 
But, actually, even in early AI, there was this idea that, no, that wasn't the right way to think about doing things at all, and that really there are two ways that you could try to build a system. 
==========
There is what was called procedural and declarative strategies. 
So we have been absolutely focused so far on declarative strategies because those are most different from things that you already know about. 
In a declarative method, the idea is that you independently ... 
articulate two different things -- you write down the knowledge about the world ... 
and then some kind of an inference strategy. 
So in logic we wrote down the knowledge about the world in terms of axioms and our inference strategy was a theorem prover. 
In these planning methods, our knowledge about the world has been the operator descriptions and we had special- purpose planning algorithms for inference. 
But still there was a sense that you describe the world the way it is without saying anything about what you're trying to do specifically. 
Then the goal comes along, and you take what you know and the goal and you take the general- purpose strategy and you kind of turn the crank for a while and out comes a prescription of what you ought to do. 
That seems very attractive because this knowledge is useful independent of what you're trying to do at the moment, right? 
And if you learn something about the laws of physics. 
If you learn something about the laws of physics, then they ought to be as applicable to, you know, catching and kicking footballs as to playing tennis. 
Well, but probably you know that there isn't so much skill transfer between passing footballs and playing tennis; and that may be because the mechanism that you're using to figure out what to do with your limbs doesn't have this structure. 
It doesn't have the structure of, oh, I have this general-purpose theory of physics and let me apply it to the particular domain. 
Rather, it seems like you just somehow directly acquire a strategy for doing those things. 
So the other sort of way to think about it is in the procedural approach you just write a programs. 
You just say how to do it. 
You could imagine writing a program, a pretty general program, for how to do things in airports. 
First you go to the check-in counter, then you do this, then you do that, then you go to the gate; it can have this, it can have loops, it can have all kinds of stuff. 
You all know how to write programs. 
And, you know, the big dirty secret of AI was that most of, or a lot of, what people were doing in this declarative way -- that was kind of complicated but beautiful and elegant in some way -- you could get at much more directly by just writing program. 
I mean not just more directly but better, more efficiently, more usefully for the particular applications. 
And now... 
There are some kinds of planning and scheduling problems that we really just have to do this way, that you couldn't just write out the programs to do the job for you. 
But there are others that aren't. 
Those of you who are maybe also taking the Embodied Intelligence class, or who have taken it before, most of the approaches in that class fall into the "write a program" category. 
Correct? 
Once you've decided that you're going to write a program, it doesn't mean that there are no more interesting questions about how to go about it. 
There are a lot of interesting ways to think about how to directly program an agent to do stuff. 
I mean you could just write a program in your favorite programming language. 
That would work. 
Other things that people have done, an old sort of style thing is production systems. 
Production systems are confusing because if you look at them at first they look a little bit like logic, but they don't -- they have imperative force. 
They tell you what to do. 
They say if this situation holds -- they're all rules that say "if this, then that". 
If this condition, then do that action. 
So they're rules that tell you how to behave. 
You could turn a triangle table into a production system. 
Right? 
If this condition, then do that action; if this other condition, then do this other action. 
So that's a way to write programs, a general way to structure programs for some kinds of situations that's a good way to do it.. 
Another thing you could do is, you know, combinations of behaviors ... 
(writes), a popular way to do robot stuff, where you essentially write a bunch of very simple programs and then describe how they can kind of take priority over one another or interact with each other in certain kinds of ways. 
So I don't want you to get the feeling after -- you know, just to kind of tie this whole section off -- there are some problems that are well addressed this way, but it is certainly not the way to try to do every problem in the world. 
And what -- people who are designing more complex robot systems, for instance, are now attempting to build architectures in multiple levels, where for instance you have something like a planner -- you know a planner or a re-planner, something like that at a high level of abstraction; and what it generates are actions but those actions are things at a level of granularity like "go out the door" or "go to Room 10" or "pick up the eraser" -- if only anybody's robot could pick up an eraser. 
They wish it could. 
But those actions are not motor voltages. 
Those don't go down to the low level, and you would not want to try to get a planner to figure out what motor voltages to use. 
So then typically you send those actions into another system, which has got some primitive behaviors say. 
And those primitive behaviors actually send out motor commands, and then quite frequently you'll have a kind of parallel system going up the other side. 
So you'll have some sensing. 
Images or something might come out of here. 
There's reasons to think this isn't exactly the right way to do stuff, but it's an interesting thing to think about anyway. 
So images or some other kind of low-level sensory data might come out here. 
You might compute some sort of primitive sensory predicates of some sort, and that might be the world view that goes into the planner/re-planner. 
So the planner/re-planner isn't interested in whether pixel 52,93 is on or off; it's interested in whether or not we're in this room. 
So, in order for it to kind of think at the level it wants to think at, it needs to understand whether or not it's in this room. 
And there's reason to think that you actually want to be making predictions for the perceptual system to check out. 
Rather than having it just try to sort of de novo decide what's going on in the world, you'd like it to kind of look at what you're expecting to see and trying to guess whether it's happening or not. 
But you may end up making a system something like that. 
So there's room to have some planning, but still most of the hard work goes on in trying to get the lower-level stuff to work right, that you're trying to apply to a robot. 
The other thing is, just by way of finishing and by way of segue, that the question about whether you want to be living in something like this regime or something like that regime has to do with how uncertain, how unreliable, the world is. 
The more reliable your actions are, the more it feels OK to just make a plan and do it. 
The less reliable, the more that you're going to have to do this kind of thing. 
But, still, the notion of a universal plan I think is saying, well, gosh, my actions aren't very predictable, but I'm going to treat them all as if -- I'm going to treat all the outcomes as if they're exactly the same likelihood. 
I don't have a way of saying, well, these bad outcomes are more likely than these other bad outcomes. 
So, for instance, imagine that I'm trying to figure out how to go to the airport, right? 
So, the strategy for -- this strategy for going to the airport says, well, I'm just going to make a plan and do it, and if it goes badly wrong, I'll decide what to do about it then. 
This is we're going to anticipate every possible thing that could go wrong -- every possible place that my plane could land instead of where it's supposed to, every possible traffic jam, every possible parking lot being filled, every possible -- you know, all four of my tires explode as I'm driving up the freeway. 
Everything! 
That's all -- there's no way to say that some of these are more worth thinking about than others. 
And that's just nuts, right? 
It seems to me that the right position between these things is to say, well, there are some things that could go wrong, and there are some things that are much more likely to go wrong than other things, and to the extent that I have mental capacity to think about, in advance, stuff that might go wrong, I'm going to want to focus on the more likely things. 
But to do that we need to have a kind of principled way of talking about more likely, and that's what we're going to do next time. 
END OF TAPE 
==========
